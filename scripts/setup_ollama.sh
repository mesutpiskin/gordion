#!/bin/bash

# Ollama Kurulum ve Test Script
# M4 Pro Max iÃ§in optimize edilmiÅŸ

echo "============================================================"
echo "Ollama Setup for Stash Agent"
echo "============================================================"
echo ""

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama bulunamadÄ±. Kuruluyor..."
    echo ""
    
    # Install Ollama
    echo "ğŸ“¦ Ollama kuruluyor (Homebrew ile)..."
    brew install ollama
    
    if [ $? -ne 0 ]; then
        echo "âŒ Homebrew kurulumu baÅŸarÄ±sÄ±z. Manuel kurulum iÃ§in:"
        echo "   curl -fsSL https://ollama.com/install.sh | sh"
        exit 1
    fi
    
    echo "âœ… Ollama kuruldu!"
else
    echo "âœ… Ollama zaten kurulu"
fi

echo ""
echo "============================================================"
echo "Ollama Servisi BaÅŸlatÄ±lÄ±yor..."
echo "============================================================"
echo ""

# Start Ollama service in background
ollama serve > /tmp/ollama.log 2>&1 &
OLLAMA_PID=$!
echo "âœ… Ollama servisi baÅŸlatÄ±ldÄ± (PID: $OLLAMA_PID)"
echo "   Log: /tmp/ollama.log"

# Wait for Ollama to start
echo ""
echo "â³ Ollama'nÄ±n baÅŸlamasÄ± bekleniyor..."
sleep 3

# Check if Ollama is running
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama servisi Ã§alÄ±ÅŸÄ±yor!"
else
    echo "âŒ Ollama servisi baÅŸlatÄ±lamadÄ±"
    exit 1
fi

echo ""
echo "============================================================"
echo "Ã–nerilen Modeller (M4 Pro Max iÃ§in)"
echo "============================================================"
echo ""
echo "ğŸš€ HIZLI MODELLER (Ã–nerilen):"
echo "   â€¢ llama3.1:8b      - HÄ±zlÄ±, genel amaÃ§lÄ± (4GB RAM)"
echo "   â€¢ mistral:7b       - Ã‡ok hÄ±zlÄ±, kompakt (4GB RAM)"
echo "   â€¢ codellama:7b     - Kod odaklÄ±, hÄ±zlÄ± (4GB RAM)"
echo ""
echo "ğŸ’ª GÃœÃ‡LÃœ MODELLER (Daha iyi kalite):"
echo "   â€¢ llama3.1:13b     - Dengeli performans (8GB RAM)"
echo "   â€¢ codellama:13b    - Kod iÃ§in optimize (8GB RAM)"
echo ""
echo "ğŸ”¥ EN GÃœÃ‡LÃœ MODELLER (En iyi kalite, yavaÅŸ):"
echo "   â€¢ llama3.1:70b     - En iyi kalite (40GB RAM)"
echo "   â€¢ codellama:34b    - Kod iÃ§in en iyi (20GB RAM)"
echo ""

# Ask which model to install
echo "============================================================"
echo "Hangi modeli kurmak istersiniz?"
echo "============================================================"
echo ""
echo "1) llama3.1:8b      (Ã–nerilen - HÄ±zlÄ±, genel amaÃ§lÄ±)"
echo "2) codellama:13b    (Kod odaklÄ±, daha gÃ¼Ã§lÃ¼)"
echo "3) mistral:7b       (En hÄ±zlÄ±, kompakt)"
echo "4) llama3.1:70b     (En gÃ¼Ã§lÃ¼ - Ã§ok RAM gerekir)"
echo "5) Manuel seÃ§im"
echo ""
read -p "SeÃ§iminiz (1-5) [1]: " choice
choice=${choice:-1}

case $choice in
    1)
        MODEL="llama3.1:8b"
        ;;
    2)
        MODEL="codellama:13b"
        ;;
    3)
        MODEL="mistral:7b"
        ;;
    4)
        MODEL="llama3.1:70b"
        ;;
    5)
        read -p "Model adÄ± girin (Ã¶rn: llama3.1:8b): " MODEL
        ;;
    *)
        MODEL="llama3.1:8b"
        ;;
esac

echo ""
echo "============================================================"
echo "Model Ä°ndiriliyor: $MODEL"
echo "============================================================"
echo ""
echo "âš ï¸  Ä°lk indirme bÃ¼yÃ¼k olabilir (4-40GB arasÄ±)"
echo "â³ LÃ¼tfen bekleyin..."
echo ""

ollama pull $MODEL

if [ $? -eq 0 ]; then
    echo ""
    echo "âœ… Model baÅŸarÄ±yla indirildi: $MODEL"
else
    echo ""
    echo "âŒ Model indirme baÅŸarÄ±sÄ±z"
    exit 1
fi

echo ""
echo "============================================================"
echo "Kurulum TamamlandÄ±!"
echo "============================================================"
echo ""
echo "âœ… Ollama servisi Ã§alÄ±ÅŸÄ±yor"
echo "âœ… Model hazÄ±r: $MODEL"
echo ""
echo "ğŸ“ .env dosyasÄ±nÄ± gÃ¼ncellemeyi unutmayÄ±n:"
echo "   AI_PROVIDER=ollama"
echo "   OLLAMA_MODEL=$MODEL"
echo ""
echo "ğŸ§ª Test etmek iÃ§in:"
echo "   python3 tests/test_ollama.py"
echo ""
echo "ğŸš€ Agent'Ä± baÅŸlatmak iÃ§in:"
echo "   python3 src/main.py"
echo ""

# Update .env file
ENV_FILE=".env"
if [ -f "$ENV_FILE" ]; then
    echo "ğŸ“ .env dosyasÄ± gÃ¼ncelleniyor..."
    
    # Update AI_PROVIDER
    if grep -q "^AI_PROVIDER=" "$ENV_FILE"; then
        sed -i '' "s/^AI_PROVIDER=.*/AI_PROVIDER=ollama/" "$ENV_FILE"
    fi
    
    # Update OLLAMA_MODEL
    if grep -q "^OLLAMA_MODEL=" "$ENV_FILE"; then
        sed -i '' "s/^OLLAMA_MODEL=.*/OLLAMA_MODEL=$MODEL/" "$ENV_FILE"
    fi
    
    echo "âœ… .env dosyasÄ± gÃ¼ncellendi"
fi

echo ""
echo "ğŸ’¡ Ä°pucu: Ollama servisi arka planda Ã§alÄ±ÅŸÄ±yor."
echo "   Durdurmak iÃ§in: pkill ollama"
echo "   Yeniden baÅŸlatmak iÃ§in: ollama serve &"
echo ""
